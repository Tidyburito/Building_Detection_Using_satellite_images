{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **THEORY**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The architecture used**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"u-net-architecture.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CODE**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing all the libraries**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version of each libraries <br>\n",
    "Name----------------------->version <br>\n",
    "Python---------------------->3.11.3 <br>\n",
    "Tensorflow------------------>2.12.0 <br>\n",
    "cv2------------------------->4.7.0 <br>\n",
    "Numpy----------------------->1.23.5 <br>\n",
    "Keras----------------------->2.12.0 <br>\n",
    "Matplotlib------------------>3.7.1 <br>\n",
    "sklearn--------------------->1.2.2 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras import backend as K\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 720 #every picture is 720x720"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Taking the images from the files and appending them into arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "jade = []\n",
    "counter1 = 0 \n",
    "for directory_path in glob.glob(\"input_2018\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        jade.append(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)      \n",
    "        img = (img.astype('float32')) / 255. \n",
    "        train_images.append(img)      #takes all the images and appends their values in a list\n",
    "        counter1 += 1\n",
    "#Convert list to array for machine learning processing        \n",
    "train_images = np.array(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\user\\Desktop\\only_building_attempt_2\\fefe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(jade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_list = [s[-16:-4] for s in jade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modified_list[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = []\n",
    "counter2 = 0\n",
    "for directory_path in glob.glob(\"mask\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_COLOR) \n",
    "        train_masks.append(mask) \n",
    "        counter2 += 1        \n",
    "#Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counter1,counter2) #sanity check if the images and mask appended are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1 = np.unique(train_masks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar1)\n",
    "print(\"\"\"The following pixel values represents the following class\n",
    "85: buildings\n",
    "170: background\n",
    "255: Null\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check for seeing if the images correspond to the correct masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "image_number = random.randint(0, len(train_images))\n",
    "print(image_number)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(train_images[image_number], (patch_size, patch_size, 3)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(train_masks[image_number], (patch_size, patch_size,3)))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Converting the images into integer coded for the machine learning algortihm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building = np.array([85,85,85])\n",
    "unlabeled = np.array([170,170,170])\n",
    "null= np.array([255,255,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_2D_label(label):\n",
    "    \"\"\"\n",
    "    Converts the RGB pixel into interger coded  \n",
    "    \"\"\"\n",
    "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
    "    label_seg [np.all(label == null,axis=-1)] = 2\n",
    "    label_seg [np.all(label==unlabeled,axis=-1)] = 0\n",
    "    label_seg [np.all(label==building,axis=-1)] = 1\n",
    "    \n",
    "    label_seg = label_seg[:,:,0]  #Just take the first channel, no need for all 3 channels\n",
    "    \n",
    "    return label_seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(train_masks.shape[0]):\n",
    "    label = rgb_to_2D_label(train_masks[i])\n",
    "    labels.append(label)    \n",
    "\n",
    "labels = np.array(labels)   \n",
    "labels = np.expand_dims(labels, axis=3) #this will convert the rgb values into integer coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar2 = np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Removing the images which we don't need**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing the images with Null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "bin = []\n",
    "counter3 = 0\n",
    "for i in range(len(labels)):\n",
    "    x = [2] in labels[i] #this will filter the images with 0 in them and remove them\n",
    "    if x is False:\n",
    "        test.append(labels[i].astype('float32'))    \n",
    "    else:\n",
    "        bin.append(i) #making a list of all the images with null values\n",
    "        counter3 += 1\n",
    "labels1 = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = []\n",
    "counter5 = 0\n",
    "for i in range(len(train_images)):\n",
    "#using the list above made to remove the images with null values\n",
    "    if i in bin:\n",
    "        counter5 += 1\n",
    "    else:\n",
    "        test2.append(train_images[i])\n",
    "train_images1 = np.array(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels1))\n",
    "print(len(bin))\n",
    "print(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "image_number = random.randint(0, len(train_images1-1))\n",
    "print(image_number)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(train_images1[image_number], (patch_size, patch_size, 3)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(labels1[image_number], (patch_size, patch_size,1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(labels1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing the images with only background**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only use this if you want pictures with both buildings and background\n",
    "bin = []\n",
    "test = []\n",
    "for i in range(len(labels1)):\n",
    "    x = [1] in labels1[i]\n",
    "    if x is True:\n",
    "        test.append(labels1[i].astype('float32'))    \n",
    "    else:\n",
    "        bin.append(i)\n",
    "        counter3 += 1\n",
    "labels2 = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test))\n",
    "print(len(bin))\n",
    "ar2 = np.unique(labels2)\n",
    "print(ar2)#doing some sanity checks to make sure all the data is getting used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = []\n",
    "counter5 = 0\n",
    "for i in range(len(train_images1)):\n",
    "#using the list above made to remove the images with null values\n",
    "    if i in bin:\n",
    "        counter5 += 1\n",
    "    else:\n",
    "        test2.append(train_images1[i])\n",
    "train_images2 = np.array(test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_images2))\n",
    "print(counter5)\n",
    "train_images2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images2.shape,labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(labels2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another sanity to make sure that all the files have been appended correctly after removal of images with null values in them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "image_number = random.randint(0, len(train_images2-1))\n",
    "print(image_number)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(train_images2[image_number], (patch_size, patch_size, 3)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(labels2[image_number], (patch_size, patch_size,1)))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Spliting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_images2, labels2, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating digital negatives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will create digital negative of every train image so model does not train only on color and learns to find more parameters\n",
    "digital_negative = []\n",
    "for i in range(len(X_train)):\n",
    "    dig_neg = 1 - X_train[i]\n",
    "    digital_negative.append(dig_neg)\n",
    "digital_negative = np.array(digital_negative)\n",
    "X_train = np.concatenate((X_train,digital_negative))\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we have made digital negative of every image we will have to append the same labels because the images class are same\n",
    "y_train = np.concatenate((y_train,y_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assign sample weights because of Imbalanced classes as the background is in the majority**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sample_weights(i,label):\n",
    "\n",
    "  one_count = np.count_nonzero(label)\n",
    "  zero_count = 518400 - one_count # every image has total 518400 values because it is an 720x720 image\n",
    "  c= 1000000 #using this constant because every image are 6 numbers\n",
    "  x = c/(2*zero_count)\n",
    "  y = c/(2*one_count)#this will find the correct sample weights such that even if the background is in the majority then also both will have equal importance\n",
    "  # The weights for each class, with the constraint that:\n",
    "  #     sum(class_weights) == 1.0\n",
    "  class_weights = tf.constant([x,y])\n",
    "  class_weights = class_weights/tf.reduce_sum(class_weights)\n",
    "\n",
    "  # Create an image of `sample_weights` by using the label at each pixel as an \n",
    "  # index into the `class weights` .\n",
    "  sample_weights = tf.gather(class_weights, indices=tf.cast(label, tf.int32))\n",
    "\n",
    "  return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = []#creating the sample weights for every image we have \n",
    "for i in range(X_train.shape[0]):\n",
    "    sample_weights1 = add_sample_weights(i,y_train[i])\n",
    "    sample_weights.append(sample_weights1)\n",
    "sample_weights = np.array(sample_weights)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_weights.shape[0])#sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Making the Deep learning Model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Convolutional Blocks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = keras.layers.Concatenate()([us, skip])\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    f = [16, 32, 64, 128, 256]\n",
    "    inputs = keras.layers.Input((patch_size, patch_size, 3))\n",
    "    \n",
    "    p0 = inputs\n",
    "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3]) #16->8\n",
    "    \n",
    "    bn = bottleneck(p4, f[4])\n",
    "    \n",
    "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss= \"binary_focal_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model.fit(X_train, y_train, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs= 30,\n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=False,\n",
    "                    sample_weight=sample_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the model performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history1\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history1\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving and loading the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(os.path.join('models','inverse_model_unet.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join('models','inverse_model_unet.h5'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making predictions using the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'C:\\Users\\user\\Desktop\\only_building_attempt_2\\output_2018'\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dpi = 144\n",
    "for i in range(result.shape[0]):\n",
    "    gun = (result[i]*255).astype(int)\n",
    "    fig = plt.figure(figsize=(936/my_dpi, 936/my_dpi), dpi=my_dpi)\n",
    "    fig = plt.imshow(gun)\n",
    "    plt.axis('off')\n",
    "    a = modified_list[i]\n",
    "    plt.savefig(f'{a}.png', bbox_inches='tight', pad_inches = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_img_number = random.randint(0, len(X_test)-1)\n",
    "\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "predicted_img = result[test_img_number]\n",
    "kernel_size = (8,8)  # Adjust the kernel size as desired\n",
    "kernel = np.ones(kernel_size, dtype=np.uint8)\n",
    "\n",
    "# Apply erosion to the image\n",
    "eroded_image = cv2.erode(result[test_img_number], kernel, iterations=1)\n",
    "sobel_x = cv2.Sobel(eroded_image*255, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(eroded_image*255, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Calculate the magnitude and convert to uint8\n",
    "gradient_magnitude = cv2.magnitude(sobel_x, sobel_y)\n",
    "gradient_magnitude = cv2.convertScaleAbs(gradient_magnitude)\n",
    "\n",
    "# Apply a threshold to obtain the edges\n",
    "threshold_value = 10  # Adjust the threshold value as desired\n",
    "edges = cv2.threshold(gradient_magnitude, threshold_value, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "eroded_image1 = cv2.erode(y_test[test_img_number], kernel, iterations=1)\n",
    "sobel_x = cv2.Sobel(result[test_img_number]*255, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(result[test_img_number]*255, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Calculate the magnitude and convert to uint8\n",
    "gradient_magnitude = cv2.magnitude(sobel_x, sobel_y)\n",
    "gradient_magnitude = cv2.convertScaleAbs(gradient_magnitude)\n",
    "\n",
    "# Apply a threshold to obtain the edges\n",
    "threshold_value = 29 # Adjust the threshold value as desired\n",
    "edges2 = cv2.threshold(gradient_magnitude, threshold_value, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "\n",
    "print(test_img_number)\n",
    "plt.figure(figsize=(12, 8)) \n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img)\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth)\n",
    "plt.subplot(234)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(predicted_img)\n",
    "plt.subplot(235)\n",
    "plt.title('Prediction after morphological functions')\n",
    "plt.imshow(eroded_image)\n",
    "plt.subplot(236)\n",
    "plt.title('Edge in the buildings')\n",
    "plt.imshow(edges)\n",
    "plt.subplot(233)\n",
    "plt.title('Edge in the building from mask')\n",
    "plt.imshow(edges2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
